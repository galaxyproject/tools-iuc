<tool id="mfa_train_tokenizer" name="MFA Train Tokenizer" version="@TOOL_VERSION@+@VERSION_SUFFIX@" profile="@PROFILE@">
    <description>train a tokenizer model from a corpus and dictionary</description>
    <macros>
        <import>macros.xml</import>
    </macros>
    <expand macro="requirements" />
    <command detect_errors="exit_code"><![CDATA[
        @PREPARE_ENV@
        @PREPARE_CORPUS@
        @PREPARE_DICTIONARY@

        ## 3. Prepare Config (Optional)
        #if $config_file:
            ln -s '$config_file' config.yaml &&
        #end if

        ## 4. Run Training
        ## Syntax: mfa train_tokenizer [OPTIONS] SOURCE_DIRECTORY DICTIONARY_PATH OUTPUT_MODEL_PATH
        mfa train_tokenizer
            corpus_dir
            $dict_arg
            '$output_model'
            --job_name 'mfa_train_tok_job'
            #if $config_file:
                --config_path config.yaml
            #end if

    ]]></command>

    <inputs>
        <expand macro="input_corpus" />
        <expand macro="input_dictionary" />

        <param name="config_file" type="data" format="yaml" optional="true" label="Configuration File" help="Optional configuration for advanced training parameters." />

    </inputs>

    <outputs>
        <data name="output_model" format="zip" label="${tool.name} on ${on_string}: Trained Tokenizer" />
    </outputs>

    <tests>
        <test expect_num_outputs="1">
            <param name="corpus_source" value="test_corpus.zip" ftype="zip" />
            
            <conditional name="dictionary_type">
                <param name="source" value="history" />
                <param name="dictionary_file" value="test_dict.txt" ftype="txt" />
            </conditional>
            
            <output name="output_model">
                <assert_contents>
                    <has_size value="200" delta="200" />
                </assert_contents>
            </output>
        </test>
    </tests>

    <help><![CDATA[
**Montreal Forced Aligner: Train Tokenizer**

This tool trains a model to split continuous text into words.

**When to use this?**

This is primarily for languages like Japanese, Chinese, or Thai that do not use whitespace to separate words. 

* You provide a **Dictionary** (the list of valid words).
* You provide a **Corpus** (text data).
* MFA learns the statistical probability of character sequences to determine where word boundaries should be placed.

**Output**

A `.zip` file containing the Tokenizer Model. You can use this in the **MFA Tokenize** tool.

    ]]></help>
    <expand macro="creators" />
    <expand macro="citations" />
</tool>