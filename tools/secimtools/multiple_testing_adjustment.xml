<tool id="secimtools_multiple_testing_adjustment" name="Multiple Testing Adjustment (MTA)" version="@WRAPPER_VERSION@">
    <description>of p-values to account for multiple testing.</description>
    <macros>
        <import>macros.xml</import>
    </macros>
    <expand macro="requirements" />
    <command><![CDATA[
multiple_testing_adjustment.py
--input $input
--uniqID $uniqID
--pval "$pval"
--alpha $alpha
--outadjusted $outadjusted
--flags $flags
    ]]></command>
    <inputs>
        <param name="input" type="data" format="tabular" label="Wide Dataset" help="Input dataset in wide format and tab separated. If not tab separated see TIP below."/>
        <param name="uniqID" type="text" size="30" value="" label="Unique Feature ID" help="Name of the column in your Wide Dataset that has unique Feature IDs."/>
        <param name="pval" type="text" size="30" value="" label="p-value column" help="Name of the column in your Wide Dataset that contains the p-values."/>
        <param name="alpha" type="float" size="6" value="0.05" label="α" help="Value of α to be used for multiple correction.  Default α = 0.05."/>
    </inputs>
    <outputs>
        <data format="tabular" name="outadjusted" label="${tool.name} on ${on_string}: Adjusted pval."/>
        <data format="tabular" name="flags" label="${tool.name} on ${on_string}: Flags."/>
    </outputs>
    <tests>
        <test>
            <param name="input"  value="ST000006_anova_fixed_with_group_summary.tsv"/>
            <param name="uniqID" value="Retention_Index" />
            <param name="pval"   value="prob_greater_than_t_for_diff_Chardonnay, Carneros, CA 2003 (CH01)-Chardonnay, Carneros, CA 2003 (CH02)" />
            <param name="alpha"  value="0.05" />
            <output name="outadjusted" file="ST000006_multiple_testing_adjustment_outadjusted.tsv" />
            <output name="flags"       file="ST000006_multiple_testing_adjustment_flags.tsv" />
        </test>
    </tests>
    <help><![CDATA[

@TIP_AND_WARNING@

**Tool Description**

The tool is designed to adjust p-values for multiple comparisons using three different methods:

(1) The Bonferroni method and two false discovery rate (FDR) methods, (2) the Benjamini-Hochberg method (BH) and (3) the Benjamini-Yekutieli method (BY).
The p-value correction can be carried out on p-values generated from the following tools: Analysis of Variance (ANOVA) Fixed Effects Model, Kruskal-Wallis Non-Parametric Test, T-test (Single Group) and T-test (Paired and/or Unpaired) in addition to p-values generated outside of these tools.
The user can specify the total type I error α value.

More details about the PH and BY methods are available in the papers:

Benjamini, Y., and Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the royal statistical society. Series B (Methodological), 289-300.

Benjamini, Y., and Yekutieli, D. (2001). The control of the false discovery rate in multiple testing under dependency. Annals of statistics, 1165-1188.

-------------------------------------------------------------------------------------------

**Input**

    - Two input datasets are required.

@WIDE@

@UNIQID@

**Name for p-value column**

    - Name of the column in your Wide Dataset that contains the p-values.

**α**

    - Value of α to be used for multiple correction.  Default α = 0.05.

-------------------------------------------------------------------------------------------

**Output**

The tool produces two TSV files:

(1) One TSV contains five columns:
	a column with unique feature IDs,
	a column of the original p-values and
	the last three columns contain the p-values adjusted using the 3 methods described above which are reflected in the column name.
(2) The second TSV file contains flags where all significant values are flagged as 1 and non-significant values are flagged as 0.

    ]]></help>
    <expand macro="citations"/>
</tool>
