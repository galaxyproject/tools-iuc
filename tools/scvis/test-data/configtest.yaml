hyperparameter: {
  optimization: {
    method: Adam,
    learning_rate: 0.01
  },

  batch_size: 512,
  max_epoch: 1,
  regularizer_l2: 0.001,

  perplexity: 10,

  seed: 1
}

architecture: {
  latent_dimension: 2,

  inference: {
    layer_size: [128, 64, 32],
  },

  model: {
    layer_size: [32, 32, 32, 64, 128],
  },

  activation: "ELU"
}
